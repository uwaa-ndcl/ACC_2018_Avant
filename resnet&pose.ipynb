{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1zwmudf3nJeyjrNhTcD8ElVkbHohpuEsl",
      "authorship_tag": "ABX9TyOnShHIOeHNkfOT4ZN68byp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uwaa-ndcl/ACC_2018_Avant/blob/master/resnet%26pose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVeIHDP8K1fp",
        "outputId": "473927e1-bf9b-4356-8e94-755ab7ef92a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data cleaning"
      ],
      "metadata": {
        "id": "JazI54rpa6KF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset source: https://cvgl.stanford.edu/projects/objectnet3d/\n",
        "import os, glob, scipy.io as sio\n",
        "from tqdm import tqdm\n",
        "\n",
        "root = '/content/drive/MyDrive/standford_pose_class_1'\n",
        "ann_dir = os.path.join(root, 'annotation')\n",
        "img_dir = os.path.join(root, 'image')\n",
        "\n",
        "clean_rel_paths = []  # only keep the readable samples\n",
        "\n",
        "for mat_path in tqdm(glob.glob(os.path.join(ann_dir, '*.mat'))):\n",
        "    base = os.path.splitext(os.path.basename(mat_path))[0]\n",
        "    try:\n",
        "        sio.loadmat(mat_path, struct_as_record=False, squeeze_me=True)\n",
        "    except NotImplementedError:\n",
        "        # v7.3 cannot be read, delete\n",
        "        print(f\"Deleting (v7.3): {mat_path}\")\n",
        "        os.remove(mat_path)\n",
        "        # delete the corresponding picsï¼ˆjpg/pngï¼‰\n",
        "        for ext in ['.jpg', '.png']:\n",
        "            img_path = os.path.join(img_dir, base + ext)\n",
        "            if os.path.exists(img_path):\n",
        "                print(f\"Deleting image: {img_path}\")\n",
        "                os.remove(img_path)\n",
        "        continue\n",
        "    except Exception:\n",
        "        # other damages, delete\n",
        "        print(f\"Deleting (corrupt): {mat_path}\")\n",
        "        os.remove(mat_path)\n",
        "        for ext in ['.jpg', '.png']:\n",
        "            img_path = os.path.join(img_dir, base + ext)\n",
        "            if os.path.exists(img_path):\n",
        "                print(f\"Deleting image: {img_path}\")\n",
        "                os.remove(img_path)\n",
        "        continue\n",
        "\n",
        "    # usable samples\n",
        "    imgs = glob.glob(os.path.join(img_dir, base + '.*'))\n",
        "    if imgs:\n",
        "        clean_rel_paths.append(os.path.relpath(imgs[0], root))\n",
        "\n",
        "print(f\"âœ… Usable samples: {len(clean_rel_paths)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptR3PnpEDE5J",
        "outputId": "2c104d76-ec2e-40f7-c0ac-a5024c0cef45"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 530/530 [00:17<00:00, 30.39it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Usable samples: 530\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataloader"
      ],
      "metadata": {
        "id": "EaMhcMEJbBH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataset check"
      ],
      "metadata": {
        "id": "7QZdZ16wbJnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see the structure of the dataset\n",
        "import scipy.io as sio, glob, os, pprint, numpy as np\n",
        "\n",
        "# root = 'class1'\n",
        "mat_path = glob.glob(os.path.join(root, 'annotation', '*.mat'))[0]\n",
        "rec  = sio.loadmat(mat_path)['record'][0][0]\n",
        "obj  = rec['objects'][0][0]\n",
        "\n",
        "vp = obj['viewpoint'][0][0]          # (1,1) â†’ struct\n",
        "print('viewpoint dtype names â†’')\n",
        "pprint.pprint(vp.dtype.names)\n",
        "\n",
        "# ä¹Ÿå¯æ‰“å°å…·ä½“æ•°å€¼çœ‹çœ‹\n",
        "for k in vp.dtype.names:\n",
        "    v = vp[k]\n",
        "    # v å¯èƒ½è¿˜æ˜¯ ndarrayï¼ŒæŠŠæ ‡é‡å€¼å–å‡ºæ¥\n",
        "    try: v = float(v[0][0])\n",
        "    except Exception: pass\n",
        "    print(f'{k:15s} â†’ {v}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8UGrxtEbLkq",
        "outputId": "a7e8f3dd-911b-4f43-b811-8c1769b598a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "viewpoint dtype names â†’\n",
            "('azimuth_coarse',\n",
            " 'elevation_coarse',\n",
            " 'azimuth',\n",
            " 'elevation',\n",
            " 'distance',\n",
            " 'focal',\n",
            " 'px',\n",
            " 'py',\n",
            " 'theta',\n",
            " 'error',\n",
            " 'interval_azimuth',\n",
            " 'interval_elevation',\n",
            " 'num_anchor',\n",
            " 'viewport')\n",
            "azimuth_coarse  â†’ 0.0\n",
            "elevation_coarse â†’ 10.0\n",
            "azimuth         â†’ []\n",
            "elevation       â†’ []\n",
            "distance        â†’ 5.207271426214868\n",
            "focal           â†’ 1.0\n",
            "px              â†’ 185.5\n",
            "py              â†’ 180.0\n",
            "theta           â†’ 0.0\n",
            "error           â†’ []\n",
            "interval_azimuth â†’ []\n",
            "interval_elevation â†’ []\n",
            "num_anchor      â†’ 12.0\n",
            "viewport        â†’ 2000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dataloader define&data augmentation"
      ],
      "metadata": {
        "id": "8WqSfVfJbUQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob, torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "import scipy.io as sio   # è¯»å– .mat\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def safe_angle(v_fine, v_coarse):\n",
        "    \"\"\"ä¼˜å…ˆå– fineï¼›è‹¥ä¸ºç©ºåˆ™ç”¨ coarse\"\"\"\n",
        "    return float(v_fine[0][0]) if v_fine.size else float(v_coarse[0][0])\n",
        "\n",
        "\n",
        "class PoseDataset(Dataset):\n",
        "    def __init__(self, root, file_list, transform=None):\n",
        "        \"\"\"\n",
        "        root       : æ ¹ç›®å½• 'class1'\n",
        "        file_list  : å›¾åƒç›¸å¯¹è·¯å¾„åˆ—è¡¨ï¼Œä¾‹å¦‚ ['images/img0001.jpg', ...]\n",
        "        transform  : torchvision transforms\n",
        "        \"\"\"\n",
        "        self.root = root\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_rel_path = self.file_list[idx]\n",
        "        img_path = os.path.join(self.root, img_rel_path)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        base = os.path.splitext(os.path.basename(img_rel_path))[0]\n",
        "        mat_path = os.path.join(self.root, 'annotation', f'{base}.mat')\n",
        "\n",
        "        rec = sio.loadmat(mat_path)['record'][0][0]\n",
        "        obj = rec['objects'][0][0]\n",
        "        vp  = obj['viewpoint'][0][0]\n",
        "\n",
        "        # ---------- è§’åº¦è¯»å– ----------\n",
        "        yaw   = safe_angle(vp['azimuth'],   vp['azimuth_coarse'])\n",
        "        pitch = safe_angle(vp['elevation'], vp['elevation_coarse'])\n",
        "        roll  = float(vp['theta'][0][0])                 # theta å§‹ç»ˆæœ‰å€¼\n",
        "\n",
        "        pose = torch.tensor([yaw, pitch, roll], dtype=torch.float32)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, pose\n"
      ],
      "metadata": {
        "id": "kuL3vjuP3e3W"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import random, numpy as np\n",
        "\n",
        "\n",
        "all_imgs = sorted(glob.glob(os.path.join(root, 'image', '*.*')))          # ç»å¯¹è·¯å¾„\n",
        "all_imgs = [os.path.relpath(p, root) for p in all_imgs]                    # å˜ä¸ºç›¸å¯¹è·¯å¾„\n",
        "\n",
        "# å›ºå®šéšæœºç§å­ä¾¿äºŽå¤çŽ°\n",
        "random.seed(42); np.random.seed(42)\n",
        "\n",
        "train_imgs, tmp = train_test_split(all_imgs, test_size=0.2, random_state=42)\n",
        "val_imgs, test_imgs = train_test_split(tmp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f'Train: {len(train_imgs)}, Val: {len(val_imgs)}, Test: {len(test_imgs)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq4swPdY43lS",
        "outputId": "2d9e3e7b-e151-4695-83d5-2c9db057c5fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 424, Val: 53, Test: 53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "IMG_SIZE   = 224  # ResNet-50 æ ‡å‡†è¾“å…¥\n",
        "\n",
        "train_tf = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "test_tf = T.Compose([\n",
        "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
        "])\n",
        "\n",
        "train_ds = PoseDataset(root, train_imgs, transform=train_tf)\n",
        "val_ds   = PoseDataset(root, val_imgs,   transform=test_tf)\n",
        "test_ds  = PoseDataset(root, test_imgs,  transform=test_tf)\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36VdUrv_5CFZ",
        "outputId": "db398d9d-89e5-4fb6-fa9a-f58630a3ba54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mj6j72Y98oB",
        "outputId": "7ad6589e-afbc-4193-ef9a-3bacab265d05"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "viewpoint dtype names â†’\n",
            "('azimuth_coarse',\n",
            " 'elevation_coarse',\n",
            " 'azimuth',\n",
            " 'elevation',\n",
            " 'distance',\n",
            " 'focal',\n",
            " 'px',\n",
            " 'py',\n",
            " 'theta',\n",
            " 'error',\n",
            " 'interval_azimuth',\n",
            " 'interval_elevation',\n",
            " 'num_anchor',\n",
            " 'viewport')\n",
            "azimuth_coarse  â†’ 0.0\n",
            "elevation_coarse â†’ 10.0\n",
            "azimuth         â†’ []\n",
            "elevation       â†’ []\n",
            "distance        â†’ 5.207271426214868\n",
            "focal           â†’ 1.0\n",
            "px              â†’ 185.5\n",
            "py              â†’ 180.0\n",
            "theta           â†’ 0.0\n",
            "error           â†’ []\n",
            "interval_azimuth â†’ []\n",
            "interval_elevation â†’ []\n",
            "num_anchor      â†’ 12.0\n",
            "viewport        â†’ 2000.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## training"
      ],
      "metadata": {
        "id": "PR50qLHUACRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### define network"
      ],
      "metadata": {
        "id": "ttYTDG8obrmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 3)   # yaw(left-right rotation), pitch(up down rotation), roll(forward-backward rotation)\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "id": "D0YZmxp05GDn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "\n",
        "EPOCHS = 15\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            pred = model(x)\n",
        "            loss = torch.sqrt(criterion(pred, y))  # RMSE\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "            n += x.size(0)\n",
        "    return total_loss / n\n",
        "\n",
        "best_val = float('inf')\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch}/{EPOCHS}')\n",
        "    for x, y in pbar:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_postfix(train_loss=loss.item())\n",
        "\n",
        "    val_rmse = evaluate(val_loader)\n",
        "    print(f'âš¡ï¸  Val RMSE: {val_rmse:.3f}')\n",
        "    if val_rmse < best_val:\n",
        "        best_val = val_rmse\n",
        "        torch.save(model.state_dict(), 'best_pose_resnet50.pth')\n",
        "        print('ðŸ”–  Model saved.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnbQXMnr5JMW",
        "outputId": "c8d50d07-dd9b-4e60-ce82-cea490628ba8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.61it/s, train_loss=814]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 26.367\n",
            "ðŸ”–  Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.87it/s, train_loss=1.83e+3]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 25.198\n",
            "ðŸ”–  Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 3/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 3/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.24it/s, train_loss=686]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 24.291\n",
            "ðŸ”–  Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.72it/s, train_loss=854]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 24.098\n",
            "ðŸ”–  Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 5/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 5/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.99it/s, train_loss=1.16e+3]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.361\n",
            "ðŸ”–  Model saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.17it/s, train_loss=1.64e+3]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.70it/s, train_loss=26.9]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 8/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 8/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.66it/s, train_loss=234]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.761\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 9/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 9/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:08<00:00,  1.70it/s, train_loss=591]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.93it/s, train_loss=1.03e+3]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.00it/s, train_loss=138]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.77it/s, train_loss=176]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 13/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 13/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.25it/s, train_loss=235]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 23.794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 14/15:   0%|          | 0/14 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 14/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:07<00:00,  1.94it/s, train_loss=427]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 24.073\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:06<00:00,  2.22it/s, train_loss=359]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âš¡ï¸  Val RMSE: 24.168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('best_pose_resnet50.pth'))\n",
        "test_rmse = evaluate(test_loader)\n",
        "print(f'ðŸŽ¯  Test RMSE (deg): {test_rmse:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofQ5bVsQb-Zj",
        "outputId": "0152d338-2113-49a1-a216-cecad4ded3bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯  Test RMSE (deg): 23.049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "419rO6FA9a32"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}